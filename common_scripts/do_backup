#!/bin/bash
#
# Script to backup a file or dir to curlbin.ignacio.systems

set -e          # stop on errors
set -u          # stop on unset variables
set -o pipefail # stop on pipe failures

# Colors for terminal output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
NC='\033[0m' # No Color

usage(){
  echo "Usage: $(basename "$0") logging_webhookid alert_webhookid file|dir recipient"
  echo "  logging_webhookid: Slack webhook ID for success notifications (format T[A-Z0-9]*/B[A-Z0-9]*/[a-zA-Z0-9]*)"
  echo "  alert_webhookid: Slack webhook ID for failure notifications (format T[A-Z0-9]*/B[A-Z0-9]*/[a-zA-Z0-9]*)"
  echo "  file|dir: Path to file or directory to backup"
  echo "  recipient: Email address for GPG encryption"
}

log_msg() {
  echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

cleanup() {
  # Clean up any temporary files
  if [ -n "${path_enc:-}" ] && [ -f "${path_enc}" ]; then
    log_msg "Cleaning up temporary file: ${path_enc}"
    rm -f "${path_enc}"
  fi
  
  if [ -n "${tar_file:-}" ] && [ -f "${tar_file}" ]; then
    log_msg "Cleaning up temporary tar file: ${tar_file}"
    rm -f "${tar_file}"
  fi
}

# Set up trap to clean up temporary files on exit
trap cleanup EXIT INT TERM

E_NOARGS=85
wh_regex="T[A-Z0-9]*\/B[A-Z0-9]*\/[a-zA-Z0-9]*"

# Check arguments
if [ -z ${1+x} ] || [ -z ${2+x} ] || [ -z ${3+x} ] || [ -z ${4+x} ]; then
  usage
  exit "$E_NOARGS"
elif ! [[ $1 =~ $wh_regex ]]; then
  log_msg "ERROR: Logging webhook format invalid. Expected format $wh_regex. Received: $1"
  usage
  exit 1
elif ! [[ $2 =~ $wh_regex ]]; then
  log_msg "ERROR: Alert webhook format invalid. Expected format $wh_regex. Received: $2"
  usage
  exit 1
elif ! test -e "$3"; then
  log_msg "ERROR: Cannot access file|dir: $3"
  usage
  exit 1
fi

logging_wh=$1
alert_wh=$2
fileordir=$3
recipient=$4
now=$(date +%d%m%y-%H%M)

# Check if GPG is installed
if ! command -v gpg &> /dev/null; then
  log_msg "ERROR: GPG is not installed. Please install it to use this script."
  exit 1
fi

# Check if curl is installed
if ! command -v curl &> /dev/null; then
  log_msg "ERROR: curl is not installed. Please install it to use this script."
  exit 1
fi

# Check if recipient key is available
if ! gpg --list-keys "${recipient}" &> /dev/null; then
  log_msg "WARNING: GPG key for recipient '${recipient}' not found in keyring."
  log_msg "Attempting to retrieve key from keyserver..."
  if ! gpg --recv-keys "${recipient}" &> /dev/null; then
    log_msg "WARNING: Could not retrieve key from keyserver. Encryption may fail."
  fi
fi

# Handle directory compression
if test -d "$fileordir"; then
  log_msg "Compressing directory: ${fileordir}"
  tar_file="/tmp/${fileordir##*/}.tar.gz"
  parent=$(dirname "$fileordir")
  cd "$parent"
  if ! sudo tar -czf "${tar_file}" "${fileordir##*/}"; then
    log_msg "ERROR: Failed to compress directory: ${fileordir}"
    exit 1
  fi
  cd - > /dev/null
  fileordir="${tar_file}"
  log_msg "Directory compressed to: ${tar_file}"
fi

file_enc="${fileordir##*/}-${now}.gpg"
path_enc="/tmp/${file_enc}"

log_msg "Encrypting file with GPG for recipient: ${recipient}"
if ! gpg --quiet --encrypt --output "${path_enc}" --yes --recipient "${recipient}" "${fileordir}"; then
  log_msg "ERROR: GPG encryption failed"
  exit 1
fi
log_msg "File encrypted successfully: ${path_enc}"

log_msg "Uploading encrypted file to curlbin.ignacio.systems..."

# Add timeout and retry logic with better error handling
max_retries=3
retry_count=0
curl_log="/tmp/curl_log_${now}.txt"

while [ $retry_count -lt $max_retries ]; do
    # Upload to curlbin.ignacio.systems
    log_msg "Attempt $((retry_count + 1)) to upload file..."
    upload_response=$(curl -s --max-time 30 -Fc=@"${path_enc}" "https://curlbin.ignacio.systems" 2>"$curl_log")
    
    # Check if we got a successful response by looking for the URL field in the JSON
    if [[ "$upload_response" == *"url"* ]]; then
        # Extract the URL from the JSON response
        if command -v jq &> /dev/null; then
            backup_url=$(echo "$upload_response" | jq -r '.url')
            suggested_url=$(echo "$upload_response" | jq -r '.suggestedUrl')
            manage_url=$(echo "$upload_response" | jq -r '.manageUrl')
            expire_at=$(echo "$upload_response" | jq -r '.expireAt')
        else
            # Fallback to basic extraction if jq is not available
            backup_url=$(echo "$upload_response" | grep -o '"url": "[^"]*"' | cut -d'"' -f4)
            suggested_url=$(echo "$upload_response" | grep -o '"suggestedUrl": "[^"]*"' | cut -d'"' -f4)
            manage_url=$(echo "$upload_response" | grep -o '"manageUrl": "[^"]*"' | cut -d'"' -f4)
            expire_at=$(echo "$upload_response" | grep -o '"expireAt": "[^"]*"' | cut -d'"' -f4)
        fi
        
        if [ -n "$backup_url" ]; then
            log_msg "${GREEN}Upload successful on attempt $((retry_count + 1))${NC}"
            break
        fi
    fi
    
    # If we get here, the upload failed
    log_msg "${RED}Upload attempt $((retry_count + 1)) failed${NC}"
    log_msg "Response received: ${upload_response:-'No response'}"
    
    retry_count=$((retry_count + 1))
    if [ $retry_count -lt $max_retries ]; then
        log_msg "Retrying in 5 seconds..."
        sleep 5
    fi
done

# Check if upload was successful
if [ -n "${backup_url:-}" ]; then
    log_msg "${GREEN}Backup performed successfully${NC}"
    log_msg "Backup URL: ${backup_url}"
    log_msg "Suggested URL: ${suggested_url}"
    log_msg "Management URL: ${manage_url}"
    log_msg "Expires at: ${expire_at}"
    
    # Create a file with the backup URLs for reference
    {
        echo "Backup URL: ${backup_url}"
        echo "Suggested URL: ${suggested_url}"
        echo "Management URL: ${manage_url}"
        echo "Expires at: ${expire_at}"
    } > "/tmp/backup_url_${now}.txt"
    log_msg "Backup URLs saved to: /tmp/backup_url_${now}.txt"
    
    # Print success message with file size information
    orig_size=$(du -h "${fileordir}" | cut -f1)
    enc_size=$(du -h "${path_enc}" | cut -f1)
    log_msg "Original size: ${orig_size}, Encrypted size: ${enc_size}"
    
    # Send success notification to Slack using logging webhook
    logging_hook="https://hooks.slack.com/services/$logging_wh"
    hostname_info=$(hostname)
    content="{\"text\":\"\u2705 \`${hostname_info}\` - Backup successful \nFile: \`${fileordir}\`\nBackup URL: \`${backup_url}\`\nExpires: \`${expire_at}\` \n\"}"
    
    log_msg "Sending success notification to logging webhook"
    webhook_result=$(curl -s -X POST -H 'Content-type: application/json' --data "${content}" "$logging_hook" || echo "Webhook call failed")
    log_msg "Webhook result: ${webhook_result}"
    
    exit 0
else
    # Upload failed completely
    log_msg "${RED}ERROR: Backup failed after $max_retries attempts${NC}"
    
    # Save file locally as fallback
    fallback_path="/tmp/backup_${file_enc}"
    cp "${path_enc}" "$fallback_path"
    log_msg "${YELLOW}Fallback backup saved to: $fallback_path${NC}"
    
    # Check if we have curl logs to include in the alert
    curl_error=""
    if [ -f "$curl_log" ]; then
        curl_error=$(head -n 10 "$curl_log")
        log_msg "Curl error details: $curl_error"
    fi
    
    # Send failure notification to Slack using alert webhook
    alert_hook="https://hooks.slack.com/services/$alert_wh"
    hostname_info=$(hostname)
    content="{\"text\":\"\u274c \`${hostname_info}\` - Backup failed \nFile: \`${fileordir}\`\nLocal backup: \`${fallback_path}\`\nError: \`${curl_error}\` \n\"}"
    
    log_msg "Sending alert to alert webhook"
    webhook_result=$(curl -s -X POST -H 'Content-type: application/json' --data "${content}" "$alert_hook" || echo "Webhook call failed")
    log_msg "Webhook result: ${webhook_result}"
    
    exit 1
fi
